<!DOCTYPE html> <html> <head> <meta charset=utf-8> <meta content='IE=edge' http-equiv=X-UA-Compatible> <meta content='' name=description> <meta content='width=device-width, initial-scale=1' name=viewport> <title>A Web 2.0 Framework for Real-time Location Intelligence</title> <link href="/stylesheets/application-d3a7d694.css" media=all rel=stylesheet /> <script src="/javascripts/application-d4c229b7.js" data-turbolinks-track=true></script> <link href='/images/favicon.ico' rel=icon> <link href='/images/apple-touch-icon-57-6b01ec75.png' rel=apple-touch-icon-precomposed> <link href='/images/apple-touch-icon-72-948b1079.png' rel=apple-touch-icon-precomposed sizes=72x72> <link href='/images/apple-touch-icon-114-a4711075.png' rel=apple-touch-icon-precomposed sizes=114x114> <link href='/images/apple-touch-icon-144-420d9fca.png' rel=apple-touch-icon-precomposed sizes=144x144> </head> <body class='family family_2007-04-19-a-web-2-0-framework-for-real-time-location-intelligence family_2007-04-19-a-web-2-0-framework-for-real-time-location-intelligence_index'> <header class=site-header role=navigation> <div class=top-bar> <a class=container href="/"><img class="logo svg" alt="" src="/images/header-logo-72c4cdf5.svg"/> <h1>Andrew Eick</h1> <p>Head in the clouds, feet in the dirt.</p> </a> </div> <nav> <ul class=left-nav> <li class=nav-home> <a class=ss-home href="/"> <span>Home</span> </a> </li> </ul> <ul> <li> <a class="ss-openbook active" href="/family"><span>Family</span> </a> </li> <li> <a class=ss-write href="/snapshot"><span>Snapshot</span> </a> </li> <li> <a class=ss-globe href="/history"><span>History</span> </a> </li> <li> <a class=ss-camera href="/portfolio"><span>Portfolio</span> </a> </li> <li> <a class=ss-send href="/contact"><span>Contact</span> </a> </li> <li> <a class=ss-user href="/about"><span>About</span> </a> </li> </ul> </nav> </header> <div class=content> <article class=post> <div class=title> <time>Apr 19th, 2007</time> <h1>A Web 2.0 Framework for Real-time Location Intelligence</h1> </div> <p> </p> <p><strong>Abstract</strong> – With increasing deployments of Global Positioning System (GPS) devices, Radio Frequency Identification (RFID) tags, and other location-aware devices, it is now possible to capture time-varying object information. In addition, existing systems such as Enterprise Resource Planning (ERP) systems emit ancillary object metadata (e.g., inventory levels in a warehouse). The challenge is how to leverage these information assets for demanding field operations scenarios such as Crisis Management, given the size and real-time nature of the data. To address the challenge, we have built a Web 2.0 framework for real-time spatial intelligence and collaboration. Our framework includes an extensible architecture for ingesting and combining spatial data across multiple formats; a fusion server for merging spatial and bespoke business data; support for spatial transformations tied to configurable business rules; and a publishing engine that pushes the combined information out for consumption in a visual, collaborative presentation layer running in standard Web browsers and on mobile devices. The result is an easily deployable system with broad reach to the field through a visual, interactive interface presenting timely, meaningful information.</p> <p><strong>Introduction</strong></p> <p> </p> <p>Crisis Management requires fast, on-the-spot decision-making by emergency responders (ERs) addressing reported incidents. Establishing a usable Common Operating Picture, or Shared Situational Awareness, for all the involved teams and individuals, possibly cross-jurisdiction, in both crisis and routine situations is essential to successful outcomes.</p> <p>Fundamental needs of ERs surrounding Shared Situational Awareness include getting critical information related to the crisis at hand in real-time in an easily digestible form for fast understanding; enabling quick, intuitive interrogation for further detail; being alerted to unusual or highly important events related to the crisis; easily and securely communicating location-based observations and information with some or all involved parties; and easily accessing the system being used from standard devices without needing to manage client software.</p> <p>Systems in the past have failed to meet the challenges posed by these needs because they were too complex for the targeted user (ERs), too limited in capability, relied on the deployment of specialized software, were too expensive to license and/or maintain, or some combination of these reasons.</p> <p>To address the challenges of providing Shared Situational Awareness for Crisis Management, we have developed a Web 2.0 framework for real-time spatial intelligence and collaboration. Our framework is unique for several reasons. First, the architecture is modular and built around open Web and geospatial standards. This open architecture simplifies integration, makes it easy to extend, and enables “bottleneck tuning” to support varying deployment scenarios (e.g., bandwidth constrained environments). Second, the publishing engine has the capability to generate output customized for consumption on various devices. These devices include thin client Scalable Vector Graphics (SVG) [1] and Asynchronous JavaScript and XML (AJAX) [2] enabled Web browsers and mobile devices. AJAX and SVG enable a rich client experience without the need to manage client software. Third, our framework includes a novel presentation layer with custom visual displays for geo-fencing, geo-tracking, bread crumbing, hot spot analysis, collaboration, and location prediction – all through thin client and mobile device interfaces.</p> <p>In this paper we describe the system in the context of Crisis Management. Specifically, we provide an outline of ER needs surrounding Shared Situational Awareness followed by a description of our framework capabilities that address those needs. We conclude with a summary of benefits.</p> <p><strong>Emergency Responder Needs</strong></p> <p>Crisis Management involves one or more teams of people and various support resources (e.g., emergency vehicles, command and control unit, radios, and medical equipment). People may be in the field (e.g., policemen, firemen, emergency medical technicians, HAZMAT responders, on-site incident commander) or off-site behind the scenes (e.g., dispatch, emergency operations center). While we refer to the people in the field as emergency responders (or sometimes “first responders”), the needs of a system supporting Shared Situational Awareness extends to the people working behind the scenes, particularly at the operations center.</p> <p>ER needs for Shared Situational Awareness support can be categorized into usability needs and system needs. First we identify the usability needs:</p> <p>(1)</p> <p>While ERs need to be presented with all the facts, it is essential the information is presented in a form that they can quickly internalize within the context of the present situation. This suggests the supporting system provide an intuitive, visual approach that enables ERs to glean immediate insight about the situation simply by glancing at the information display.</p> <p>(2)</p> <p>ERs need to know the “what”, the “where” and the “when” about relevant events and objects. Understanding how a group of events are related across both location and time contributes to improved Situational Awareness. This suggests the supporting system present the information (the “what”) in both geospatial (the “where”) and temporal (the “when”) forms from which associations can be derived.</p> <p>(3)</p> <p>ERs need to know where and when critical events related to the crisis have occurred, and where new related events occur as they happen. This suggests the supporting system provide well-defined data ingest protocols and efficient, robust data management.</p> <p>Further, knowledge of current positions of emergency vehicles and personnel that have responded or could respond to an incident is essential in the coordination of the overall effort. A recent history of where a responder has been is useful for understanding things like surveillance coverage. These needs suggest the supporting system provide the ability to represent multiple types of data (e.g., events, objects, paths).</p> <p>(4)</p> <p>ERs need quick access to more detail than what might be initially presented. Detail might be specific to the event itself (e.g., type of chemical spill) or contextual information surrounding the event (e.g., see aerial photography of the affected site at a granular level). This suggests the supporting system provide an interactive interface that allows the user to interrogate and interact with the displayed data.</p> <p>(5)</p> <p>ERs will have on-the-spot observations that will be pertinent to the rest of the team who are both in the field and in the operations center. Most of the time location will be a key element of those observations. The ER will need an easy way to identify/describe the location – typically an area – and make others aware of it, and perhaps include commentary in some form capturing key observations. This suggests the supporting system provide built-in location-based collaboration.</p> <p>(6)</p> <p>ERs want to be told when something of high interest occurs – particularly something that deviates from the norm – that might be related to the crisis, e.g., a looting crime occurring in or around an evacuated area, or an emergency vehicle leaving or entering a designated quarantined zone. This suggests the supporting system provide a flexible, rules-based approach for triggering predefined actions associated with events and object positions relative to designated zones.</p> <p>System needs are as follows:</p> <p>(7)</p> <p>The system that supports the above usability needs must be readily and easily accessible by ERs, operations center personnel, and other parties involved in the management of the crisis. The system must support common client devices with standard environments without imposing specialized software requirements. Updates and/or upgrades to the system must not require changes to the client environment. This suggests a Web-based, thin client system that requires no software downloads or plug-ins.</p> <p>(8)</p> <p>The system must easily integrate into existing environments/applications. This suggests an open system based on accepted, industry standards.</p> <p><strong>Web 2.0 Approach to Crisis Management</strong></p> <p>Our approach was to build a framework on Web 2.0 from the ground-up to support real-time spatial intelligence and collaboration and a thin client deployment. Core capabilities as they relate to the Crisis Management needs identified in the previous section are described below.</p> <p><strong>(1) **</strong>At-a-Glance Understanding**</p> <p>Figure 1 shows a simple Crisis Management application built on our framework. The map provides location intelligence of a number of 911 calls, including the crisis incident (HAZMAT). The translucent orange area on the map represents the affected area to be evacuated, as indicated by the tear-away tooltip shown.</p> <p>The Timelines at the bottom provide a temporal view of the items shown in the map. The top Timeline provides a summary view of all notable events that have occurred so far throughout the day. The bottom Timeline provides a detailed hourly view of a subset of the day represented by the blue lens in the top Timeline, roughly 10:30am to 2:30pm.</p> <p><a href="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image002%5B2%5D.gif"><img alt="" alt="" src="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image002%5B1%5D.gif"/></a></p> <p>Figure 1: This sample Crisis Management Application provides at-a-glance insight to support Situational Awareness.</p> <p>The map and Timeline provide an intuitive understanding of where and when events occurred. The icons themselves provide contextual information about the type of event (i.e., HAZMAT versus petty theft versus assault). Note that a given item is represented with the same icon in the map and Timelines. This helps to see not only what kind of events occurred, but which events occurred when.</p> <p><strong>(2) **</strong>Relating Location and Time**</p> <p>The map and Timeline are linked. Pointing your mouse at an item in the map highlights it in the Timeline, as shown in Figure 2, and vice versa, and shows detail in a pop-up tooltip.</p> <p>The association between location and time can be seen across multiple items by sweep-selecting a group, as shown in Figure 3. We can see quite clearly that three of the four events (which had close proximity to each other) we swept over in the map occurred very close in time.</p> <p><a href="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image004%5B2%5D.gif"><img alt="" alt="" src="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image004%5B1%5D.gif"/></a></p> <p>Figure 2: Get detail and see association of an item's location and time by pointing your mouse at it.</p> <p><a href="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image006%5B2%5D.gif"><img alt="" alt="" src="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image006%5B1%5D.gif"/></a></p> <p>Figure 3: Linked Map and Timelines enable ERs to easily associate event location and time.</p> <p>We also employ automatic “aging” of events whereby the points/icons gradually fade with time (and possibly other factors), The points eventually fade completely from the display. This is used as a way to manage data cache size with real-time data feeds as well as provide a visually effective way to relate location and time.</p> <p><strong>(3) **</strong>Real-Time Events and ER Positions**</p> <p>In the sample application shown in Figure 4, items are automatically being ingested into the system. The user does not need to manually refresh the data.</p> <p>Behind the scenes, event data is being generated through 911 calls and stored in other existing databases. Our client supports the notion of a Data Connector, which in this sample application is configured to access the framework’s Tracking Server through its Web Service interface to get at the 911 event data. The Data Connector polls the Web Service at regular intervals for new events (the data could also be pushed to the Data Connector). It then intelligently adds the new events to the data cache, possibly rolling off old events that have expired based on application settings.</p> <p>In Figure 4 there are two types of items being displayed: events (911 calls) and objects (current ER positions). These are represented as separate “data overlays” on top of the map and can be toggled on or off independently via the navigation panel at the left.</p> <p>Behind the scenes, ER vehicle locations originate from a Global Positioning System (GPS) source. The GPS data is ingested through the framework’s Tracking server. Contextual information about the items, such as the squad car name and the icon being displayed, is ingested from a different system, fused with the location data, converted to GeoRSS, and sent to the client.</p> <p>Only the latest reading for each ER vehicle is displayed. However, the recent positions can be shown in the form of a “bread crumb” trail attached to the current position. This is shown in Figure 4.</p> <p><a href="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image008%5B2%5D.gif"><img alt="" alt="" src="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image008%5B1%5D.gif"/></a></p> <p>Figure 4: Objects (Emergency Responder positions) are displayed along with events. Their positions can change in real-time. "Bread crumbing" (pathing) is used to show where the objects have recently been.</p> <p>Finally, note that only events are shown in the Timeline. The ER vehicle readings are not. This is because we are interested only in the current positions and where they have recently been. The timestamp for these readings are uninteresting since they are all taken at predefined intervals.</p> <p><strong>(4) **</strong>Detail on Demand**</p> <p>Our Web 2.0 framework provides a rich user experience. There are a number of built-in interactions the user can leverage to see more detail or additional context such as</p> <ul> <li> <p>Pan and/or zoom the map(s) (multiple maps can be leveraged with synchronized panning and zooming). </p> </li> <li> <p>Pan and/or zoom the Timelines (Timelines support synchronized panning, so in our example, as you pan the top Timeline, the bottom Timeline automatically adjusts to show events positioned within the blue lens). </p> </li> <li> <p>Zoom to a selected set of items. </p> </li> <li> <p>Allow multiple map layers to be overlaid on the display. </p> </li> <li> <p>Add more (raster) detail to the map through the selection of additional map layers (this will be dependent on the WMS source being used). </p> </li> <li> <p>Adjust the transparency of the top map to see the bottom map (e.g., blend street map with close up aerial photography to get a better sense of the structures and land use of the area surrounding the incident). </p> </li> <li> <p>Show/hide other available data overlays like public transportation routes and stops. </p> </li> <li> <p>Display items as points rather than icons. </p> </li> <li> <p>Change the color of the events (e.g., to reflect priority/importance). </p> </li> <li> <p>Click on “More Detail…” in an event’s context menu to pull up a Web page providing up-to-date detail on the event and background information about the hazard. </p> </li> </ul> <p>In Figure 5, we have zoomed one level down to the area where the HAZMAT incident occurred. We then brought up the linked mini-map, which provides a magnified aerial photography view of the area represented under the blue lens in the street map. The aerial view provides useful context for ERs.</p> <p><a href="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image010%5B2%5D.gif"><img alt="" alt="" src="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image010%5B1%5D.gif"/></a></p> <p>Figure 5: ERs can interact with the Map, Timeline and displayed data to get at more detail on demand. Synchronized panning and zooming are standard interactions. In this illustration a mini-map is synchronized with the street map. It is used to provide a magnified aerial view of the area positioned underneath the blue lens of the street map.</p> <p> </p> <p><em>Behind the scenes</em>¾Our framework leverages Web 2.0 technology, which is largely asynchronous JavaScript and XML, also referred to as AJAX. With AJAX, information is asynchronously downloaded to the browser, cached by the JavaScript, and displayed by the client when the user requests it. The net effect is an instantaneous response, without a disruptive page refresh. This makes possible a <em>direct manipulation</em> user interface, strongly preferred by users [3], but not possible with traditional (Web 1.0) applications due to the latency between the request and response and the disruptive nature of the page refresh [4].</p> <p><strong>(5) **</strong>Communicate Location-based Information**</p> <p>The orange polygon in our example represents the initial evacuation area that was created by an ER or someone in the operations center shortly after assessing the crisis incident earlier in the day. Figure 6 shows the area being reconfigured based on a new assessment. As shown, the polygon is drawn with the mouse or stylus (depending on the user’s device). Further, the user can attach commentary in the form of notes or audio recordings.</p> <p><a href="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image012%5B2%5D.gif"><img alt="" alt="" src="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image012%5B1%5D.gif"/></a></p> <p>Figure 6: ERs can mark the map directly and attach observations.</p> <p>Markings and attachments are automatically propagated to other ERs by our framework’s Collaboration Server, as illustrated in Figure 7. User-drawn zones are rendered as a separate data overlay. ERs have the option to show/hide these zones.</p> <p><a href="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image014%5B2%5D.gif"><img alt="" alt="" src="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image014%5B1%5D.gif"/></a></p> <p>Figure 7: Markings automatically propagate to other ERs' displays.</p> <p><strong>(6) **</strong>Alert Me to Important or Unusual Matters**</p> <p>Figure 8 shows an alert triggered by an ER vehicle entering the quarantined zone. The alert was triggered based on a business rule previously set up to kick off an alert whenever an ER vehicle enters or exits a quarantined zone. In other words, even zones created on the fly by ERs will automatically be subjected to pre-defined business rules.</p> <p><a href="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image016%5B2%5D.gif"><img alt="" alt="" src="/content/binary/WindowsLiveWriter/AWe.0FrameworkforRealtimeLocationIntelli_BE65/clip_image016%5B1%5D.gif"/></a></p> <p>Figure 8: ERs are alerted to important occurrences based on configurable business rules.</p> <p>Our Tracking Server provides Business Rules and Alerting modules to define rules and actions, dynamically perform calculations as location data is received, and trigger corresponding alerts.</p> <p><strong>(7) **</strong>Broad Reach (Thin Client)**</p> <p>Our Web 2.0 approach enables rich client interaction while maintaining broad reach through a thin client interface that imposes no specialized software requirements on the client device.</p> <p><strong>(8) **</strong>Easy Integration**</p> <p>Our framework supports a Representational State Transfer (REST) Service Oriented Architecture (SOA) allowing easy integration into existing environments and applications. In addition, it provides flexible, standards-based imagery and feature data ingest subsystems.</p> <p><em>Imagery</em>¾Our frameowrk supports the OGC standards WMS and WFS. It also is able to read imagery formats like RPF (CADRG and CIB), MrSID and JPEG2000. Further, it provides a WMS interface to all these sources, including other WMS’s, enabling a single view to consist of layers from multiple image sources. This flexible imagery ingest enables imagery sources to be hooked up with little effort.</p> <p><em>Data</em>¾Our framework supports standard protocols for feature data ingest including GeoRSS [5] and Geospatial Markup Language (GML) [6]. GeoRSS extends the popular Really Simple Syndication (RSS) protocol [7] with location information. Standard GeoRSS supports points, lines, circles, and polygons. Our framework also supports thincGeoRSS, an extension to GeoRSS that supports additional shapes like ellipses and the specification of common attributes like fill color, line thickness and transparency. In addition, our framework can ingest JavaScript Object Notation (JSON) [8] as well as JavaScript itself. Supporting standard protocols as such simplifies the process of connecting up data.</p> <p><em>Client</em>¾Our framework imposes no restrictions on the client except requiring Scalable Vector Graphics (SVG) full version for client-side rendering of feature data. SVG is supported natively in Firefox, and as a plug-in (from Adobe) for Internet Explorer. Although our framework currently supports only SVG for the rendering, it leverages a rendering abstraction layer, making it easy to support other rendering engines such as Microsoft VML or XAML.</p> <p><strong>Conclusions</strong></p> <p>A usable Shared Situational Awareness is crucial for successful Crisis Management. The high-pressure, stressful conditions under which ERs must operate makes it imperative that the tools they use are easily accessible, reliable, and intuitive. Our thin client approach provides reach (accessibility) and does not affect the client environment, increasing reliability. GeoBoost’s novel, highly visual displays present the information in a format digestible by the ER at-a-glance. ERs are informed of critical events through custom alerts triggered by business rules tailored for Crisis Management.</p> <p>Getting at the right information as events occur and sharing key observations are also crucial to Shared Situational Awareness. Our framework was designed to deal with the complexities of efficiently handling real-time data. It was built on Web 2.0 technology from the ground up, providing a rich environment for on-the-spot interrogation of the information and its surrounding context. It also enables ERs to share location-based observations simply by marking/annotating the map, with backend support to propagate those observations to the involved ER teams.</p> <p>Finally, our framework’s flexible architecture and standards support make it easy to integrate into existing environments.</p> <p>Simply put, the capabilities of our framework are well-aligned with Crisis Management needs. One challenge at hand is supporting handheld devices, like SmartPhones and PocketPCs, where SVG and other standards are still ill-defined. Our current approach is to provide client-side code specific to the device, and then revisit a true thin client once standards on those devices become more settled.</p> <p>Our Web 2.0 approach coupled with visualization and strong server-side functionality offers a number of key advantages surrounding reach, ease of use, richness, and integration that lend itself to Crisis Management and many other problem domains.</p> <p><strong>References</strong></p> <p> </p> <p>[1] <em>Scalable Vector Graphics (SVG) 1.1 Specification</em>, W3C Recommendation, 14 January 2003, www.w3.org.</p> <p>[2] <em>Building Rich Web Applications with Ajax</em>. IEEE Computer 2005; 38(10): 14-17.</p> <p>[3] <em>Designing the User Interface</em>, Addison Wesley, Third Edition, 1998.</p> <p>[4] Stuart Card, Jock Mackinlay, Ben Shneiderman, <em>Readings__ in Information Visualization: Using Vision to Think,</em> Morgan Kaufmann, 1999.</p> <p>[5] <em>Encoded Objects for RSS feeds</em>, April, 2006, www.georss.org.</p> <p>[6] <em>OpenGIS® Geography Markup Language (GML) Encoding Specification</em>, OGC 02-023r4, Version 3.00, 18 December 2002.</p> <p>[7] <em>RSS 2.0 Specification</em>, blogs.law.harvard.edu/tech/rss.</p> <p>[8] <em>Introducing JSON</em>, RFC 4627, www.JSON.org.</p> <ul class=tags> <li><a href="/family/2007/">2007</a></li> <li><a href="/family/tags/work/">work</a></li> </ul> </article> <ul class='pagination post-pagination'> <li class=prev> <a href="/family/2007-04-15-yaml-shmaml/"><div class='pagination-direction ss-navigateleft'>Previous</div> <p>YAML SHMAML</p> </a> </li> <li class=next> <a href="/family/2007-04-22-the-revoluxion-has-a-new-home/"><div class='pagination-direction ss-navigateright right'>Next</div> <p>The revolUXion has a new home...</p> </a> </li> </ul> </div> <footer class=site-footer> <div class=container> <nav> <h3 class=section-title>Andy Eick</h3> <ul> <li><a href="/">Home</a></li> <li><a href="/about">About</a></li> <li><a href="/contact">Contact</a></li> <li><a href="//missionfocus.com">My Company</a></li> <li><a href="//imintel.org">My Institute</a></li> </ul> </nav> <nav> <h3 class=section-title>Blogs</h3> <ul> <li><a href="/family">Family</a></li> <li><a href="/snapshot">Snapshot</a></li> <li><a href="/history">History</a></li> </ul> </nav> <nav> <h3 class=section-title>Pages</h3> <ul> <li><a href="/portfolio">Portfolio</a></li> <li><a href="/bookshelf/index.html">Bookshelf</a></li> <li><a href="//soccer-peeps.com">Jasmine's Soccer</a></li> <li><a href="//eick-home.us.quickconnect.to/photo">Photo Archive</a></li> </ul> </nav> <div class=copyright> <p>&copy; 1999-2014</p> </div> </div> </footer> </body> </html>